{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.preprocessing import QuantileTransformer, StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    " \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder  \n",
    "from sklearn.compose import ColumnTransformer  \n",
    "from sklearn.pipeline import Pipeline  \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier  \n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.metrics import accuracy_score, classification_report  \n",
    "import xgboost as xgb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set(style=\"whitegrid\")\n",
    "input_train_filepath = sys.argv[1]\n",
    "traffic_df = pd.read_csv(\"..\\Traffic_analysis\\Traffic.csv\")\n",
    "traffic_two_month_df = pd.read_csv(\"..\\Traffic_analysis\\TrafficTwoMonth.csv\")\n",
    "# Combine datasets\n",
    "traffic_df['Source'] = 'OneMonth'\n",
    "traffic_two_month_df['Source'] = 'TwoMonth'\n",
    "combined_df = pd.concat([traffic_df, traffic_two_month_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#查看异常数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除异常数据\n",
    "这个函数使用四分位数法（IQR）来确定异常值，并从数据集中删除它们。该方法对数值列特别有效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Traffic Situation'] = combined_df['Traffic Situation'].astype('category').cat.codes\n",
    "combined_df['Hour'] = pd.to_datetime(combined_df['Time'], format='%I:%M:%S %p').dt.hour\n",
    "combined_df['Weekend'] = combined_df['Day of the week'].isin(['Saturday', 'Sunday'])\n",
    "# Identify and remove outliers\n",
    "def remove_outliers(df, columns):\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "vehicle_counts = ['CarCount', 'BikeCount', 'BusCount', 'TruckCount']\n",
    "combined_df = remove_outliers(combined_df, vehicle_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data using QuantileTransformer\n",
    "scaler = QuantileTransformer(output_distribution='normal')\n",
    "combined_df[['CarCount', 'BikeCount', 'BusCount', 'TruckCount']] = scaler.fit_transform(combined_df[['CarCount', 'BikeCount', 'BusCount', 'TruckCount']])\n",
    "\n",
    "\n",
    "# Prepare the features and target\n",
    "X = combined_df.drop(columns=['Traffic Situation'])\n",
    "y = combined_df['Traffic Situation']\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Accuracy: 0.9902522935779816\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       333\n",
      "           1       0.98      1.00      0.99       122\n",
      "           2       0.98      0.97      0.97       238\n",
      "           3       0.99      0.99      0.99      1051\n",
      "\n",
      "    accuracy                           0.99      1744\n",
      "   macro avg       0.99      0.99      0.99      1744\n",
      "weighted avg       0.99      0.99      0.99      1744\n",
      "\n",
      "XGBoost Model Accuracy: 0.9988532110091743\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       333\n",
      "           1       1.00      1.00      1.00       122\n",
      "           2       1.00      0.99      1.00       238\n",
      "           3       1.00      1.00      1.00      1051\n",
      "\n",
      "    accuracy                           1.00      1744\n",
      "   macro avg       1.00      1.00      1.00      1744\n",
      "weighted avg       1.00      1.00      1.00      1744\n",
      "\n",
      "Support Vector Machine Model Accuracy: 0.9174311926605505\n",
      "Support Vector Machine Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       333\n",
      "           1       0.85      0.72      0.78       122\n",
      "           2       0.93      0.75      0.83       238\n",
      "           3       0.92      0.96      0.94      1051\n",
      "\n",
      "    accuracy                           0.92      1744\n",
      "   macro avg       0.91      0.85      0.88      1744\n",
      "weighted avg       0.92      0.92      0.92      1744\n",
      "\n",
      "Gradient Boosting Model Accuracy: 0.9988532110091743\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       333\n",
      "           1       1.00      1.00      1.00       122\n",
      "           2       1.00      0.99      1.00       238\n",
      "           3       1.00      1.00      1.00      1051\n",
      "\n",
      "    accuracy                           1.00      1744\n",
      "   macro avg       1.00      1.00      1.00      1744\n",
      "weighted avg       1.00      1.00      1.00      1744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Preprocessing pipeline for numeric and categorical features\n",
    "numeric_features = ['CarCount', 'BikeCount', 'BusCount', 'TruckCount', 'Total', 'Hour']\n",
    "categorical_features = ['Time', 'Date', 'Day of the week', 'Source', 'Weekend']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# # 创建预处理管道  \n",
    "# preprocessor = ColumnTransformer(  \n",
    "#     transformers=[  \n",
    "#         ('num', StandardScaler(), numeric_features),  \n",
    "#         ('cat', OneHotEncoder(), categorical_features)  \n",
    "#     ])  \n",
    "\n",
    "# 定义各个模型管道  \n",
    "rf_model = Pipeline(steps=[  \n",
    "    ('preprocessor', preprocessor),  \n",
    "    ('classifier', RandomForestClassifier(random_state=42))  \n",
    "])  \n",
    "\n",
    "xgb_model = Pipeline(steps=[  \n",
    "    ('preprocessor', preprocessor),  \n",
    "    ('classifier', xgb.XGBClassifier(random_state=42))  \n",
    "])  \n",
    "\n",
    "svm_model = Pipeline(steps=[  \n",
    "    ('preprocessor', preprocessor),  \n",
    "    ('classifier', SVC(random_state=42,probability=True))  \n",
    "])  \n",
    "\n",
    "gb_model = Pipeline(steps=[  \n",
    "    ('preprocessor', preprocessor),  \n",
    "    ('classifier', GradientBoostingClassifier(random_state=42))  \n",
    "])  \n",
    "\n",
    "# 训练随机森林模型  \n",
    "rf_model.fit(X_train, y_train)  \n",
    "\n",
    "# 训练XGBoost模型  \n",
    "xgb_model.fit(X_train, y_train)  \n",
    "\n",
    "# 训练支持向量机模型  \n",
    "svm_model.fit(X_train, y_train)  \n",
    "\n",
    "# 训练梯度提升模型  \n",
    "gb_model.fit(X_train, y_train)  \n",
    "\n",
    "# 对测试集进行预测  \n",
    "rf_y_pred = rf_model.predict(X_test)  \n",
    "xgb_y_pred = xgb_model.predict(X_test)  \n",
    "svm_y_pred = svm_model.predict(X_test)  \n",
    "gb_y_pred = gb_model.predict(X_test)  \n",
    "\n",
    "# 评估模型表现  \n",
    "print(\"Random Forest Model Accuracy:\", accuracy_score(y_test, rf_y_pred))  \n",
    "print(\"Random Forest Classification Report:\")  \n",
    "print(classification_report(y_test, rf_y_pred))  \n",
    "\n",
    "print(\"XGBoost Model Accuracy:\", accuracy_score(y_test, xgb_y_pred))  \n",
    "print(\"XGBoost Classification Report:\")  \n",
    "print(classification_report(y_test, xgb_y_pred))  \n",
    "\n",
    "print(\"Support Vector Machine Model Accuracy:\", accuracy_score(y_test, svm_y_pred))  \n",
    "print(\"Support Vector Machine Classification Report:\")  \n",
    "print(classification_report(y_test, svm_y_pred))  \n",
    "\n",
    "print(\"Gradient Boosting Model Accuracy:\", accuracy_score(y_test, gb_y_pred))  \n",
    "print(\"Gradient Boosting Classification Report:\")  \n",
    "print(classification_report(y_test, gb_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Model  Accuracy  Precision    Recall  F1 Score\n",
      "0           Random Forest  0.990252   0.990257  0.990252  0.990233\n",
      "1                 XGBoost  0.998853   0.998855  0.998853  0.998851\n",
      "2  Support Vector Machine  0.917431   0.916876  0.917431  0.915059\n",
      "3       Gradient Boosting  0.998853   0.998855  0.998853  0.998851\n",
      "\n",
      "Classification Reports:\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       333\n",
      "           1       0.98      1.00      0.99       122\n",
      "           2       0.98      0.97      0.97       238\n",
      "           3       0.99      0.99      0.99      1051\n",
      "\n",
      "    accuracy                           0.99      1744\n",
      "   macro avg       0.99      0.99      0.99      1744\n",
      "weighted avg       0.99      0.99      0.99      1744\n",
      "\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       333\n",
      "           1       1.00      1.00      1.00       122\n",
      "           2       1.00      0.99      1.00       238\n",
      "           3       1.00      1.00      1.00      1051\n",
      "\n",
      "    accuracy                           1.00      1744\n",
      "   macro avg       1.00      1.00      1.00      1744\n",
      "weighted avg       1.00      1.00      1.00      1744\n",
      "\n",
      "Support Vector Machine Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       333\n",
      "           1       0.85      0.72      0.78       122\n",
      "           2       0.93      0.75      0.83       238\n",
      "           3       0.92      0.96      0.94      1051\n",
      "\n",
      "    accuracy                           0.92      1744\n",
      "   macro avg       0.91      0.85      0.88      1744\n",
      "weighted avg       0.92      0.92      0.92      1744\n",
      "\n",
      "Gradient Boosting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       333\n",
      "           1       1.00      1.00      1.00       122\n",
      "           2       1.00      0.99      1.00       238\n",
      "           3       1.00      1.00      1.00      1051\n",
      "\n",
      "    accuracy                           1.00      1744\n",
      "   macro avg       1.00      1.00      1.00      1744\n",
      "weighted avg       1.00      1.00      1.00      1744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,f1_score,precision_score,recall_score\n",
    "\n",
    "results = {  \n",
    "    'Model': ['Random Forest', 'XGBoost', 'Support Vector Machine', 'Gradient Boosting'],  \n",
    "    'Accuracy': [  \n",
    "        accuracy_score(y_test, rf_y_pred),  \n",
    "        accuracy_score(y_test, xgb_y_pred),  \n",
    "        accuracy_score(y_test, svm_y_pred),  \n",
    "        accuracy_score(y_test, gb_y_pred)  \n",
    "    ],  \n",
    "    'Precision': [  \n",
    "        precision_score(y_test, rf_y_pred, average='weighted'),  \n",
    "        precision_score(y_test, xgb_y_pred, average='weighted'),  \n",
    "        precision_score(y_test, svm_y_pred, average='weighted'),  \n",
    "        precision_score(y_test, gb_y_pred, average='weighted')  \n",
    "    ],  \n",
    "    'Recall': [  \n",
    "        recall_score(y_test, rf_y_pred, average='weighted'),  \n",
    "        recall_score(y_test, xgb_y_pred, average='weighted'),  \n",
    "        recall_score(y_test, svm_y_pred, average='weighted'),  \n",
    "        recall_score(y_test, gb_y_pred, average='weighted')  \n",
    "    ],  \n",
    "    'F1 Score': [  \n",
    "        f1_score(y_test, rf_y_pred, average='weighted'),  \n",
    "        f1_score(y_test, xgb_y_pred, average='weighted'),  \n",
    "        f1_score(y_test, svm_y_pred, average='weighted'),  \n",
    "        f1_score(y_test, gb_y_pred, average='weighted')  \n",
    "    ],  \n",
    "}  \n",
    "\n",
    "# 将结果转化为DataFrame  \n",
    "results_df = pd.DataFrame(results)  \n",
    "\n",
    "# 打印模型比较结果  \n",
    "print(results_df)  \n",
    "\n",
    "# 输出详细分类报告（可选）  \n",
    "print(\"\\nClassification Reports:\")  \n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, rf_y_pred))  \n",
    "print(\"XGBoost Classification Report:\\n\", classification_report(y_test, xgb_y_pred))  \n",
    "print(\"Support Vector Machine Classification Report:\\n\", classification_report(y_test, svm_y_pred))  \n",
    "print(\"Gradient Boosting Classification Report:\\n\", classification_report(y_test, gb_y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(n_classes):  \n",
    "#     fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], rf_y_prob[:, i])  \n",
    "#     roc_auc[i] = auc(fpr[i], tpr[i])  \n",
    "\n",
    "# # 绘制 ROC 曲线  \n",
    "# plt.figure(figsize=(10, 8))  \n",
    "\n",
    "# for i in range(n_classes):  \n",
    "#     plt.plot(fpr[i], tpr[i], lw=2, label='Class {0} (AUC = {1:0.2f})'.format(classes[i], roc_auc[i]))  \n",
    "\n",
    "# # 绘制对角线  \n",
    "# plt.plot([0, 1], [0, 1], 'k--', lw=2)  \n",
    "\n",
    "# # 设置图形属性  \n",
    "# plt.xlim([0.0, 1.0])  \n",
    "# plt.ylim([0.0, 1.05])  \n",
    "# plt.xlabel('False Positive Rate')  \n",
    "# plt.ylabel('True Positive Rate')  \n",
    "# plt.title('Receiver Operating Characteristic (ROC) Curve')  \n",
    "# plt.legend(loc=\"lower right\")  \n",
    "# plt.grid()  \n",
    "\n",
    "# # 显示图形  \n",
    "# plt.show()  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "12d9c065a59539a14a3ee05dcce491e834d222100a37cc8927a456fa9268f310"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
